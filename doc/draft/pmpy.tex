\newcommand\obseq{\stackrel{\sim}{=}}
\newcommand\CS{\{c,\sigma\}}
\newcommand\CpSp{\{c',\sigma'\}}
\newcommand\numCS[1]{\{c_{#1},\sigma_{#1}\}}

%\newcommand\cred[3]{#1 \dashrightarrow (#2,#3)}
\newcommand\tstep[3]{#1 \lightning (#2,#3)}
\newcommand\stept{\lightning\!\lightning}
\renewcommand\step[3]{#1 \stept (#2,#3)}

\newcommand\BigStep{\Downarrow}


\section{Technical Background}

In this section we describe a generic language of transactions and
define an idealized semantics for concurrent transactions called the
atomic semantics, in which there are no interleaved effects on the
shared state. 
%
The model preliminaries generalize those provided previously~\cite{PMPY}.
%
We also define a notion of \emph{good} configurations
and in the next section we will define how one can warp from a 
configuraiton that is not good to one that is.

\subsection{Operations and States}

We assume a set $M$ of method calls or operations (\eg\
  \texttt{ht.put('a',5)}).
%
State is represented in terms of
logs of operation records. An operation record (or, simply, an ``operation'')
$
    \op = \langle \opname, \lstack_1, \lstack_2, \opid \rangle
$
is a tuple consisting of the operation name $m$, 
a thread-local pre-stack $\lstack_1$ (method arguments),
a thread-local post-stack $\lstack_2$ (method return values),
and a unique identifier $\opid$.
%
We assume a predicate $\fresh{\opid}$ that holds provided that $\opid$
is globally unique (details omitted for lack of space).
%
In the atomic semantics defined below, the shared state $\OPL :
\textsf{list } \op$ is an ordered list of operations.
%
We use notations such as $\OPL_1\cdot\OPL_2$ and $\OPL\cdot \op$ to
mean append and appending a singleton, resp.

\begin{parameter}[From logs to states: $\allowedt{}$] 
We require a prefix-closed predicate on operation lists $\allowed{\OPL}$
that indicates whether an operation log $\OPL$ corresponds to a state.
% The sequential specification
%   is a predicate on operation lists: $\allowed{\OPL}$. We require that it
%   be prefix closed.
\end{parameter}

\noindent
For convenience we will also write $\OPL \allows \langle m, \lstack_1,
\lstack_2, \opid\rangle$ which simply means 
$\allowed{\OPL \cdot \langle m, \lstack_1,\lstack_2, \opid\rangle}$.
%
For example, if we have a simple TM
based on memory read/write operations we expect
$\;\;\allowed{\OPL\cdot \langle \texttt{a := x}, [x \mapsto 5], [x
  \mapsto 5, a \mapsto 5], \opid\rangle}$,
but 
$\;\;\neg \allowed{\OPL\cdot \langle \texttt{a := x}, [x \mapsto 5], [x
  \mapsto 5, a \mapsto 3], \opid\rangle}$ or more elaborate
specifications that involve multiple tasks.
%
Ultimately, we expect the $\allowed{}$ predicate to be induced by the
implementation's operations on the state, $\llbracket op\rrbracket :
\mathcal{P}(\mathsf{State} \times \mathsf{State})$, and the initial
states, $I$. 
% If we give a denotation to logs as $\llbracket \OPL \cdot op
% \rrbracket \equiv \llbracket \OPL \rrbracket ; \llbracket op
% \rrbracket$, and $\llbracket \epsilon \rrbracket \equiv I$ , where $
% S ; R \equiv \{ s' \mid \exists s \in S. (s,s') \in R \}$. Then we
% can define $\allowed{\OPL}$ simply by checking if the denotation is
% non-empty, $(\llbracket \OPL \rrbracket \neq \emptyset)$.

\paragraph{Operational equivalence.}
We define a precongruence over operation logs $\OPL_1 \opeq \OPL_2$
coinductively, by requiring that all \allowedt\ extensions of the log $\OPL_1$, are also \allowedt\ extension to the log $\OPL_2$. 
% This definition will ultimately be used in the simulation between
% \PMPY{} and an atomic machine.
We use a coinductive definition so that the precongruence can be
defined up to all infinite suffixes.
%\begin{definition}[Shared log precongruence $\opeq$] For all $\OPL_1, \OPL_2$,
$$
\infer={\OPL_1 \opeq \OPL_2} 
%   {\deduce{\allowed{\OPL_1}}  {\allowed{\OPL_2}}
   {  \allowed{\OPL_1} \Rightarrow \allowed{\OPL_2}
     & \forall \op.\   (\OPL_1 \cdot \op) \opeq (\OPL_2 \cdot \op)}
$$
We use a double-line here to indicate greatest fixpoint.
%\end{definition}
%
Informally, the above definition says that 
there is no sequence of observations we can make of $\OPL_2$, that we can't also make of $\OPL_1$. 
This is more general than just considering the set of states reached from executing the first log is included in the second:
unobservable state differences are also permitted. 


\subsection{Language}




Threads execute code $c$ from some programming language that
includes thread forking, transactions $\tx{c}$,
method names such as $m$, and a \skipt\ statement. As done
elsewhere~\cite{pmpy}, we abstract away the programming
  language with a few semantic functions:
%
\begin{description}
\item[$\step{c}{m}{c'}$:] Within a transaction, code $c$ can be reduced to the pair
  $(m,c')$.  That is, $m$ is a next reachable method call in the
  reduction of $c$, with remaining code $c'$.

\item[$\tstep{c}{t}{c'}$:] Outside of a transaction, code $c$ can be reduced to the pair
  $(t,c')$.  Here $c'$ is the remaining code, and $t$ is either
  a local state update, or a transaction or a thread fork.

\item[$\nothing{c}$:] This predicate is true provided that there is a
  reduction of $c$ to $\skipt$ that does not encounter a method call.
\end{description}
%
These functions allow us to obtain a simple semantics, despite an
expressive input language, by introducing functions to resolve
nondeterminism between method operation names and at the end of a
transaction. As an example, one might use the generic language:
\[ \begin{array}{rcl}
  c &::=& c_1\plust c_2 \MOR c_1 \semit c_2
      \MOR (c)^* \MOR \skipt \MOR \tx{c} \MOR \opname
\end{array} \]
%
which consists of nondeterministic choice, sequential
composition, and nondeterministic looping.
%
We assume that code is well-formed in that a single operation name $\opname$ 
is always contained within a transaction. 



\newcommand\myT{T}
\newcommand\fork[1]{\texttt{fork }#1}
\newcommand\local[1]{\texttt{local }#1}
\newcommand\txnstep[1]{\;\underrightharpdown{\;#1\;}\;}
\newcommand\txnstept[1]{\underrightharpdown{\;#1\;}}


\begin{figure}
\figbox{\footnotesize
{\bf Unconstrained Machine Rules} $\xrightarrow{u}$
$$
\infer[\text{\sc UFin}]{ 
  \As_1 \cdot (c,\sigma) \cdot \As_2, G  \xrightarrow{u}
  \As_1 \cdot \As_2, G 
}{
  \nothing{c}
}
$$
$$
\infer[\text{\sc UFork}]{ 
  \As_1 \cdot (c,\sigma) \cdot \As_2, G  \xrightarrow{u}
  \As_1 \cdot (c_2,\sigma) \cdot (c',\sigma) \cdot \As_2, G 
}{
  \tstep{c_1}{\fork{c}}{c_2}
}
$$
$$
\infer[\text{\sc ULocal}]{ 
  \As_1 \cdot (c,\sigma) \cdot \As_2, G  \xrightarrow{u}
  \As_1 \cdot (c',\sigma') \cdot \As_2, G 
}{
  \tstep{c}{\local{R}}{c'} & R\ \sigma\ \sigma'
}
$$
$$
\infer[\text{\sc UTxn}]{ 
  \As_1 \cdot (\tx{c_1},\sigma) \cdot \As_2, G  \xrightarrow{u}
  \As_1 \cdot (c_2,\sigma') \cdot \As_2, G\cdot \langle m,\sigma,\sigma' \rangle
}{
  \step{\tx{c_1}}{m}{c_2} &
  G \allows \langle m,\sigma,\sigma' \rangle
}
$$
}
\caption{\label{fig:unconstrained} Unconstrained transition system.}
\end{figure}

\subsection{Unconstrained Transition System}

We defined a generic transition system $\xrightarrow{u}$ in which threads may
interleave their effects however they please, shown in Figure~\ref{fig:unconstrained}. Clearly, this transition
system is not serializable.

 The semantics is a relation
$\xrightarrow{u}$ over pairs consisting of a list of concurrent
threads $\As$ and a shared state $\OPL$. 
A single thread $(c,\sigma)\in\As$ is a code $c$ and local state $\sigma$. 

The unconstrained machine can take a {\sc UFin} step when there is a thread
$(c,\sigma)$ that can complete, \ie~$\nothing{c}$.
%
The {\sc UFork} rule allows a new thread
$(c',\sigma)$ to be forked from thread $(c,\sigma)$.
%
The {\sc ULocal} rule involves manipulating the thread-local state
$\sigma$ to $\sigma'$.
%
Finally, the {\sc UTxn} rule allows a thread executing transaction
code $\tx{c_1}$ to take a single step to $c_2$, applying the effects
of $m$ directly to the shared log $G$.

\subsection{Atomic Transition Systems}

We next define a simple atomic semantics $\xrightarrow{a}$,
given in Figure~\ref{fig:atomic}
in which transactions are executed instantly, without interruption
from concurrent threads.

The $\xrightarrow{a}$ rules {\sc AFin, AFork, ALocal} showin in 
Figure~\ref{fig:atomic}(b) are similar to
their counterparts in $\xrightarrow{u}$.
%
However, the {\sc ATxn} rule says that if thread executing code $c_1$ can reduce to a 
transaction $\tx{c'}$, then the transaction $c'$ is executed
atomically by the big step rules $\BigStep$ described next.

Figure~\ref{fig:atomic}(a) illustrates the
big step semantics $\BigStep$, which uses $\stept$ and $\nothing{}$ 
(rules {\sc BSStep} and {\sc BSFin}, respectively). These rules
scan through the nondeterminism in $\tx{c}$ to find a next operation
name $m$ or a path to $\skipt$ denoting the end of the transaction.
%
{\sc BSStep} can be taken provided that the operation $\langle m,\sigma,\sigma'\rangle$ is
permitted and that $(c_2,\sigma')$ can be
entirely reduced to $(\sigma'',\OPL_2)$.
%  Note that there a new operation identifier $\opid_1$
% is introduced. We require $\opid_1$ to be globally unique
% (formalization of \textsf{fresh} is omitted for lack of space).

%\red{explain bsstep. we go from $\OPL_1$ to $\OPL_2$ .... bsfin
%  basically copies the $\OPL$ from left of $\Downarrow$ to the right}








\begin{figure}
\figbox{\footnotesize
(a) {\bf Atomic Machine Big Step Transaction Rules} $\BigStep$
$$
\infer[\text{\sc BSFin}]{
  (c,\sigma),\OPL \BigStep c,\OPL
}{\nothing{c}}
\qquad
\infer[\text{\sc BSStep}]{
  (c,\sigma),\OPL_1 \BigStep \sigma'',\OPL_2
}{
  \deduce{
    (c_2,\sigma'),
    \OPL\cdot[\langle m,\sigma,\sigma' \rangle]
   \BigStep \sigma'',\OPL_2
 }{
   \deduce{\OPL_1 \allows \langle m,\sigma,\sigma' \rangle}
   {\step{c}{m}{c_2}}
 }
}
$$
(b) {\bf Atomic Machine Rules} $\xrightarrow{a}$
$$
\infer[\text{\sc AFin}]{ 
  \As_1 \cdot (c,\sigma) \cdot \As_2, G  \xrightarrow{a}
  \As_1 \cdot \As_2, G 
}{
  \nothing{c}
}
$$
$$
\infer[\text{\sc AFork}]{ 
  \As_1 \cdot (c,\sigma) \cdot \As_2, G  \xrightarrow{a}
  \As_1 \cdot (c_2,\sigma) \cdot (c',\sigma) \cdot \As_2, G 
}{
  \tstep{c_1}{\fork{c}}{c_2}
}
$$
$$
\infer[\text{\sc ALocal}]{ 
  \As_1 \cdot (c,\sigma) \cdot \As_2, G  \xrightarrow{a}
  \As_1 \cdot (c',\sigma') \cdot \As_2, G 
}{
  \tstep{c}{\local{R}}{c'} & R\ \sigma\ \sigma'
}
$$
$$
\infer[\text{\sc ATxn}]{ 
  \As_1 \cdot (c_1,\sigma) \cdot \As_2, G  \xrightarrow{a}
  \As_1 \cdot (c_2,\sigma') \cdot \As_2, G'
}{
  \tstep{c_1}{\tx{c'}}{c_2} &
  (c',\sigma),G \BigStep \sigma',G'
}
$$
}
\caption{\label{fig:atomic} Atomic semantics of concurrent threads.}
\end{figure}

\subsection{Serializable Transition Systems}


\begin{definition}[Serializable transition system]
For all $\Ts,\OPL$, we say that a fragment 
$\xrightarrow{ser}$ of transition system $\xrightarrow{}$ is
serializable provided that 
$\xrightarrow{ser}$ simulates $\xrightarrow{a}$.
\end{definition}

\red{explain what simulates means}

As previously shown, the Push/Pull transition system is such a
serializable transition system~\cite{PMPY}.

\begin{definition}[Good configuration]
A configuration $\Ts,\OPL$ is \emph{good} provided that it is reachable in
some serializable transition system $\xrightarrow{ser}$
\end{definition}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Trace Warping}

The idea of trace warping is to, at some point of execution, jump to
an alternate trace that is consistent what what we have observed so
far. 

\newcommand\rc[2]{\textsf{rc}(#1,#2)}
\begin{definition}[Reference configuration]
For a given transition system with initial configuration $\Ts_0,G_0$,
we define a \emph{reference configuration}, denoted
$\rc{\Ts,G}$ to be given by the fixpoint
$$
\infer{\rc{\Ts_0}{G}}{}
\qquad
\infer{\rc{\Ts'}{G''}}{
   \rc{\Ts}{G}
&  \Ts,G \xrightarrow{ser}^{*} \Ts',G'
&  G'' \opeq G'
}
$$
\end{definition}

\paragraph{Warping correctness.} The goal of warping is simple. For a reference
configuration $\Ts_0,G_0$, when we have 
$\Ts_0,G_0 \xrightarrow{u}^{*} \Ts,G$, we wish to
\[ \begin{array}{rl}
   \text{Find } \Ts',G'' \text{ such that}&
      \Ts_0,G_0 \xrightarrow{s} \Ts',G'\\
  \text{and}&G' \opeq G''
\end{array} \]

\paragraph{Warping utility.}
In particular, we would like to find a $\Ts',G''$ that can be 
\emph{easily computed} from $\Ts,G$.



\section{Static Computation of Warp Destinations}

\paragraph{Abstract state.}
Let $\hat{\Sigma} = \Ts \times G$, denoted $\hat{\sigma} = (\Ts,G)$.

\newcommand\ts{\bar{t}}

\paragraph{Concrete state.}
Let $\Sigma = \gamma(\Ts \times G)$ be the concrete states, denoted $\sigma = (\ts,g)$.

\newcommand\Pietrot{{\cal P}ietro}

Discover a $\Pietrot : \hat{\Sigma} \rightarrow \hat{\Sigma}
\rightarrow \wp({\hat{\Sigma}})$, representing the current abstract
state, the reference abstract state, and a set of possible destination
abstract states.


\newcommand\llangle{\langle\!\langle}
\newcommand\rrangle{\rangle\!\rangle}

\section{Dynamic Warping}

\newcommand\Pengt{{\cal P}eng}
Given $\Pietrot$, the runtime system implements a function
denoted $\Pengt : \sigma \rightarrow \hat{\sigma} \rightarrow \hat{\sigma} \rightarrow \sigma$. 


Runtime tracks the current concrete state $\sigma$,
current \emph{abstract state} $\hat{\sigma}$ and the last
\emph{abstract reference state} $\hat{\sigma}_0$. Thus, we denote the runtime
configuration as
$$
    c =  \llangle \sigma,\hat{\sigma},\hat{\sigma}_0 \rrangle 
\;\;\;\text{ or, expanding }
    \llangle (\ts,g),(\Ts,G),(\Ts_0,G_0) \rrangle 
$$
That is, threads are in state $\ts$, shared state $g$, tracked abstract state
$(\Ts,G)$ and tracked abstract reference state $(\Ts_0,G_0)$.

There are then the following rules for steps in the runtime system:

$$
\infer=[\text{\bf Diverge}]{
   \llangle \sigma,\hat{\sigma},\hat{\sigma}_0 \rrangle 
  \hookrightarrow^{*}
   \llangle \sigma',\hat{\sigma}',\hat{\sigma}_0 \rrangle 
}{ ... }
$$


$$
\infer=[\text{\bf Warp}]{
  \llangle \Ts_i,g_i,G_i,G_0 \rrangle
  \hookrightarrow
  \llangle \Ts_i,g',G',G_0 \rrangle
}{
  & G' \in \Pietrot(\Ts,G_0,G_i)
  & g' = \Pengt(g,G_i,G')
}
$$

$$
\infer=[\text{\bf Commit}]{
  \llangle \Ts_i,g_i,G_i,G_0 \rrangle
  \hookrightarrow
  \llangle \Ts_i,g',G',G' \rrangle
}{ ... }
$$

$$
\infer=[\text{\bf Step}]{
  \llangle \Ts,g,G,G_0 \rrangle
  \hookrightarrow
  \llangle \Ts',g',G',G_0 \rrangle
}{
  g \in \gamma(G)
& \Ts,G \xrightarrow{P\! P} \Ts',G'
& g' \in \gamma(G')}
$$

\vfill
\pagebreak

\bigskip 
\bigskip 
\bigskip 

\red{THIS STUFF MIGHT BE DEAD}

PMPY works because it records old states, so you can jump backwards
and then roll forwards.


Formally, a ``warp'' from a configuration $\Ts,G$ to another
configuration $\hat{\Ts},\hat{G}$ can be thought of two steps:
\begin{enumerate}
\item Taking some $n$ steps to another warp configuration:
  $\Ts,G \xrightarrow{}^{*} \Ts',G'$
\item Swapping the shared log $G'$ with observationally equivalent
  $\hat{G}$. That is,  $\hat{G} \opeq G'$
\end{enumerate}

% $$
% \infer[\text{\sc warp}]{ \Ts, G \xrightarrow{\textsf{warp}} \hat{\Ts}, \hat{G} }
% {
%   \begin{array}{lll}    
%     \text{\underline{Local crit.}} &: \Ts,G \xrightarrow{}^{*} \Ts',G'\\
%     \text{\underline{Global crit.}} &: G' \opeq \hat{G} & \text{(implies \allowedt)}\\
%   \end{array}
% }
% $$

%    \forall `G.\ `G \text{ prefix of } G.\\
%    \text{\underline{Local crit.}} &: \forall \{\hat{c},\hat{\sigma},\hat{L}\} \in \hat{\Ts}.\  \lfloor  \hat{G} \rfloor_{\hat{t}} \sim L


%    \exists \hat{\OPL} = \numOP{1} \cdots \numOP{n}.\\
%\allowed{\hat{\OPL}} \\

In practice, there are many warp configurations that can be calculated
conveniently. For one, uncommitted transactions can rollback (dropping
their effects) and then some number of (intereleaved) steps can be taken.
%
It is often convenient to think of a \emph{reference point}, which is
a previously reached configuration $\Ts_0,G_0$ from which one might
compute subsequently reachable warp points $\hat{\Ts},\hat{\OPL}$.


%\item jump each thread $\CSL\in \Ts$ to $\CpSpLp\in\hat{\Ts}$ such that:\\
%    $c' = c$ (could relax this in the future)\\
    
\begin{theorem}[Serializability]
Corollary to the serializability of the Push/Pull model~\cite{pmpy}.
\end{theorem}


\paragraph{Discussion}

This section carves out a large space of possibilities for where one
might warp to. Some things to consider:

\begin{itemize}
\item Pessimistic/Optimistic destinations 
  (our implementation does Pessimistic)
\item Serial-vs-Serializable destinations
  (our implementation does Serial).\\
  For serializabile, the criteria of {\sc push} and {\sc pull} give
  sufficient conditions in terms of left/right-movers.
\end{itemize}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
